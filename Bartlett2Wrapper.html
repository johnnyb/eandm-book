<?xml version="1.0" encoding="iso-8859-1" ?> 
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//RU" 
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">  
<!--http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd-->  
<html xmlns="http://www.w3.org/1999/xhtml"  
> 
<head><title>Calculating Software Complexity Using the Halting Problem</title> 
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1" /> 
<meta name="generator" content="TeX4ht (http://www.cse.ohio-state.edu/~gurari/TeX4ht/)" /> 
<meta name="originator" content="TeX4ht (http://www.cse.ohio-state.edu/~gurari/TeX4ht/)" /> 
<!-- xhtml,html --> 
<meta name="src" content="Bartlett2Wrapper.tex" /> 
<meta name="date" content="2014-03-07 11:40:00" /> 
<link rel="stylesheet" type="text/css" href="Bartlett2Wrapper.css" /> 
</head><body 
>
                                                                                   
                                                                                   
       <div class="maketitle">
                                                                                   
                                                                                   
                                                                                   
                                                                                   

<h2 class="titleHead">Calculating Software Complexity Using the Halting
Problem</h2>
 <div class="author" ></div><br />
<div class="date" ></div>
       </div>
<div class="center" 
>
<!--l. 1--><p class="noindent" >
</p><!--l. 1--><p class="noindent" ><span 
class="cmcsc-10x-x-172">J<span 
class="small-caps">o</span><span 
class="small-caps">n</span><span 
class="small-caps">a</span><span 
class="small-caps">t</span><span 
class="small-caps">h</span><span 
class="small-caps">a</span><span 
class="small-caps">n</span> B<span 
class="small-caps">a</span><span 
class="small-caps">r</span><span 
class="small-caps">t</span><span 
class="small-caps">l</span><span 
class="small-caps">e</span><span 
class="small-caps">t</span><span 
class="small-caps">t</span></span></p></div>
<div class="center" 
>
<!--l. 1--><p class="noindent" >
</p><!--l. 1--><p class="noindent" >The Blyth Institute</p></div>
       <div 
class="abstract" 
>
<div class="center" 
>
<!--l. 3--><p class="noindent" >
</p><!--l. 3--><p class="noindent" ><span 
class="cmbx-10x-x-109">Abstract</span></p></div>

<a 
 id="dx1-2"></a>
<a 
 id="dx1-3"></a>
      <!--l. 6--><p class="indent" >    <span 
class="cmr-10x-x-109">Calculating the complexity of software projects is important to software</span>
      <span 
class="cmr-10x-x-109">engineering as it helps in estimating the likely locations of bugs as well as</span>
      <span 
class="cmr-10x-x-109">the number of resources required to modify certain program areas. Cyclomatic</span>
      <span 
class="cmr-10x-x-109">complexity  is  one  of  the  primary  estimators  of  software  complexity  which</span>
                                                                                   
                                                                                   
      <span 
class="cmr-10x-x-109">operates  by  counted  branch  points  in  software  code.  However,  cyclomatic</span>
      <span 
class="cmr-10x-x-109">complexity assumes that all branch points are equally complex. Some types of</span>
      <span 
class="cmr-10x-x-109">branch points require more creativity and foresight to understand and program</span>
      <span 
class="cmr-10x-x-109">correctly than others. Specifically, when knowledge of the behavior of a loop</span>
      <span 
class="cmr-10x-x-109">or recursion requires solving a problem similar to the halting problem, that</span>
      <span 
class="cmr-10x-x-109">loop has intrinsically more complexity than other types of loops or conditions.</span>
      <span 
class="cmr-10x-x-109">Halting-problem-like  problems  can  be  detected  by  looking  for  loops  whose</span>
      <span 
class="cmr-10x-x-109">termination conditions are not intrinsically bound in the looping construct.</span>
      <span 
class="cmr-10x-x-109">These types of loops are counted to find the program complexity. This metric</span>
      <span 
class="cmr-10x-x-109">is orthogonal to cyclomatic complexity (which remains useful) rather than as a</span>
      <span 
class="cmr-10x-x-109">substitute for it.</span>
</p>
</div>
       <h3 class="sectionHead"><span class="titlemark">1   </span> <a 
 id="x1-10001"></a>Complexity Metrics in Software</h3>
<a 
 id="dx1-1001"></a>
<!--l. 12--><p class="noindent" >Managing software development is often about managing risks - knowing which tasks are
likely to take more time than others, which features are more likely to impact others, how
much testing will be required to make sure that a feature is solid, and whether a bug fix or
a feature implementation requested right before release will be more likely to make the
code more stable or lead to other bugs.
</p><!--l. 14--><p class="indent" >       One of the key considerations of risk management is software complexity. Complex
software is inherently more difficult to build, test, and maintain. Therefore, it is critical for
software development managers to know which parts of code are most complex and
therefore more likely to incur failures if modified.
</p><!--l. 16--><p class="noindent" >
</p>
       <h3 class="sectionHead"><span class="titlemark">2   </span> <a 
 id="x1-20002"></a>A Brief History of Software Complexity Metrics</h3>
<a 
 id="dx1-2001"></a>
<!--l. 19--><p class="noindent" >Early complexity metrics were based almost entirely on the amount of code produced.
Therefore, a function which contained 10 lines of code was considered more complex than
one which contained only 5. However, since &#8220;lines&#8221; of code often varies due to stylistic
differences, Halstead developed a set of measures based on the number of operators and
operands present within the code (<a 
href="#Xkearney">Kearney et&#x00A0;al.</a>,&#x00A0;<a 
href="#Xkearney">1986</a>).
<a 
 id="dx1-2002"></a>
<a 
 id="dx1-2003"></a>
</p><!--l. 23--><p class="indent" >       Lines of code and related metrics are still often used for software effort estimation,
but its use in analyzing code complexity has fallen away. It quickly became clear that
                                                                                   
                                                                                   
not all code is the same, and some operators are inherently more complex than
others. Specifically, the decision structure of the program was inherently more
complex than the computations. Cyclomatic complexity was created to measure the
size of the decision structure of the program (<a 
href="#Xmccabe">McCabe</a>,&#x00A0;<a 
href="#Xmccabe">1976</a>). This is done by
creating a graph of all basic code blocks as nodes and then adding edges which show
how control can move between them. The formula for calculating the complexity
is:
</p>
       <table 
class="equation"><tr><td><a 
 id="x1-2004r1"></a>
       <center class="math-display" >
<img 
src="Bartlett2Wrapper0x.png" alt="E - N  + T
" class="math-display"  /></center></td><td class="equation-label">(1)</td></tr></table>
<!--l. 27--><p class="nopar" >
</p><!--l. 29--><p class="indent" >       <span 
class="cmmi-12">E </span>is the number of edges, <span 
class="cmmi-12">N </span>is the number of nodes, and <span 
class="cmmi-12">T </span>is the number of
terminating nodes (entry and exit points - usually 2).
</p><!--l. 31--><p class="indent" >       Cyclomatic complexity is extremely useful in determining how to test software. The
cyclomatic complexity of a program is also the minimum number of tests needed to cover
every control flow branch of a program. If the cyclomatic complexity of a program
is 5, then at least 5 tests must be devised to test every branch of code. Such
tests do not guarantee total coverage of all possible test conditions, but they
will verify that every statement in the program will contribute to at least one
test.
<a 
 id="dx1-2005"></a>
</p><!--l. 34--><p class="indent" >       The ABC metric is a simplified metric combining aspects of both lines of code and
cyclomatic complexity. It works by simply counting the number of assignment statements,
the number of branches (direct flow control shifts - i.e., function calls), and the number of
conditionals (<a 
href="#Xfitzpatrick">Fitzpatrick</a>,&#x00A0;<a 
href="#Xfitzpatrick">1997</a>, pp.&#x00A0;2&#8211;3). These can then be analyzed on a whole program,
per-module, or per-function basis, to give an overview of complexity and size of a software
program.
</p><!--l. 36--><p class="noindent" >
                                                                                   
                                                                                   
</p>
       <h3 class="sectionHead"><span class="titlemark">3   </span> <a 
 id="x1-30003"></a>Deeper Difficulties in Software</h3>
<a 
 id="dx1-3001"></a>
<a 
 id="dx1-3002"></a>
<a 
 id="dx1-3003"></a>
<a 
 id="dx1-3004"></a>
<!--l. 42--><p class="noindent" >While each of the previously-mentioned metrics have their usefulness, none of
them get at the deeper difficulties that make software projects complex. Many
programming languages attempt to remove the inherent difficulties within software.
Some, like COBOL, attempt to remove the mathematical notation common to
programming languages. Others, like Java, try to simplify software by encapsulating
related methods into objects. Visual programming languages, such as Flowcode,
turn all software into visual representations, allowing the user to drag and drop
flowchart-like components to accomplish programming tasks. The idea is that it is the
text-based nature of the software which causes complexity and confusion within
software.
<a 
 id="dx1-3005"></a>
</p><!--l. 45--><p class="indent" >       While each of these actually do relieve certain specific problems in software
development, none of them are able to remove the complexity of software development
because the complexity is inherent in the nature of software development itself. What
makes software development difficult is its open-ended nature. Most general-purpose
programming languages today are universal in nature - that is, they can perform any
computable function that any other programming language can perform. Thus,
they are open-ended - the types of operations that they perform are entirely
specifiable by the programmer and are not restricted.<a 
 id="dx1-3006"></a> Universal programming
languages are chaotic - that is, there is no easy mapping between programs, data, and
results. Therefore, predicting the output over a wide swath of code and data can be
difficult.
<a 
 id="dx1-3007"></a>
</p><!--l. 49--><p class="indent" >       Languages are chaotic because of arbitrary looping structures. Interestingly, this is
precisely the same part that causes it to be open-ended. Arbitrary looping structures allow
a programmer to generate any possible computable function. As such, they also allow a
programmer to write programs whose results are chaotic. In practical terms, arbitrary
looping structures are <span class="obeylines-h"><span class="verb"><span 
class="cmtt-12">while</span></span></span> statements, <span class="obeylines-h"><span class="verb"><span 
class="cmtt-12">jump</span></span></span>/<span class="obeylines-h"><span class="verb"><span 
class="cmtt-12">goto</span></span></span> statements, recursive functions, and
continuations, though others may be possible.
<a 
 id="dx1-3008"></a>
<a 
 id="dx1-3009"></a>
</p><!--l. 53--><p class="indent" >       Occasionally, the solution to this problem has been to reduce the scope of the
language. SuperGlue is one language which is specifically designed to be as expressive as
possible while avoiding constructs that lead to complexity (<a 
href="#Xmcdirmid">McDirmid</a>,&#x00A0;<a 
href="#Xmcdirmid">2006</a>). However,
ultimately, to get beyond the originally conceived computational bounds of the
programming language, universality, as well as the complexity that goes with it, are
                                                                                   
                                                                                   
required.
</p><!--l. 55--><p class="noindent" >
</p>
       <h3 class="sectionHead"><span class="titlemark">4   </span> <a 
 id="x1-40004"></a>The Halting Problem as an Insight Problem</h3>
<a 
 id="dx1-4001"></a>
<!--l. 58--><p class="noindent" >As discussed elsewhere in this volume, some problems are not amenable to analytical
analysis and require insight in order to solve them (<a 
href="#Xbartlett1">Bartlett</a>,&#x00A0;<a 
href="#Xbartlett1">2014</a>;&#x00A0;<a 
href="#Xholloway">Holloway</a>,&#x00A0;<a 
href="#Xholloway">2014</a>).
Neither are such problems computable - no computer is capable of calculating these
problems. One such problem that is relevant is the halting problem.
<a 
 id="dx1-4002"></a>
</p><!--l. 61--><p class="indent" >       The halting problem states that, given a universal language, there is no program
that can be written which will tell if any arbitrary program written in that language will
ever complete (i.e., halt). This is not based on the size of the program code, but rather
on the nature of the constructs available. This is not to say that one could not
write a program to tell if certain subsets of programs written in that language
will halt, but there could not be a program to tell if any given program would
halt.
</p><!--l. 63--><p class="indent" >       What is intriguing about this, as noted by <a 
href="#Xbartlett1">Bartlett</a>&#x00A0;(<a 
href="#Xbartlett1">2014</a>), is that computer
programmers seem to be able to possess this power to some degree. Since the complexity of
problems assigned to them are arbitrarily hard (i.e., management, not the programmer,
often decides what must be done), and the reason that arbitrarily hard programs are
possible is because of the open-ended nature of universal programming languages (the parts
of the language which <span 
class="cmti-12">create </span>the chaos are precisely the ones <span 
class="cmti-12">required </span>for programs of
arbitrary complexity), it can be said that human programmers are generally reliable halting
problem solvers.
<a 
 id="dx1-4003"></a>
</p><!--l. 66--><p class="indent" >       There are cases (usually coming from number theory) where it is not known whether
or not programs (even very simple ones!) halt. These seem to indicate that there are
different levels of difficulty and different levels of insight required to make determinations.
Some might even use these cases to argue against the general ability of humans to reliably
solve the halting problem. However, the advancement of science and mathematics
actually depends on the ability of humans to be able to accomplish such tasks. In
other words, if the ability of humans to figure out such problems is doubted, then
the progress of science itself is brought into question. Should mathematicians
stop looking for answers in number theory? Or is it better to assume that the
proper insight will come one day? The ability of programmers to reliably solve
halting problems in their daily work should lend hope to the mathematicians that
someone will eventually be able to have the insight to solve their problems as well.
<a 
 id="dx1-4004"></a>
                                                                                   
                                                                                   
</p><!--l. 69--><p class="noindent" >
</p>
       <h3 class="sectionHead"><span class="titlemark">5   </span> <a 
 id="x1-50005"></a>Using the Halting Problem to Measure Software Complexity</h3>
<a 
 id="dx1-5001"></a>
<!--l. 73--><p class="noindent" >The trouble with insight problems is that they are not reliably solved by individuals. They
are unreliably solvable - in other words, a solution is possible, but there is no
analytic procedure to do so. Even worse, if programmers do not realize that they are
looking at an insight problem, they might not know that special care must be
taken.
</p><!--l. 75--><p class="indent" >       So how is an insight problem in code recognized? Since the types of programming
structures which make a program universal have already been determined (i.e., arbitrary
looping structures), those structures in code can therefore be detected.
</p><!--l. 77--><p class="indent" >       For most programming languages, the main structures which must be detected are
the following:
<a 
 id="dx1-5002"></a>
<a 
 id="dx1-5003"></a>
</p><!--l. 81--><p class="indent" >
      </p><ol  class="enumerate1" >
      <li 
  class="enumerate" id="x1-5005x1">Loops  where  the  iterations  are  not  implicit  in  the  control  structure  (called
      <span 
class="cmti-12">open-ended loops</span>)
      </li>
      <li 
  class="enumerate" id="x1-5007x2">Recursive functions (which are just another way of implementing open-ended
      loops)</li></ol>
<!--l. 86--><p class="indent" >       For open-ended loops, consider the following two programs that each print out the
square of every number in an array:
</p>
       <hr class="figure" /><div class="figure" 
>
                                                                                   
                                                                                   
<a 
 id="x1-5008r1"></a>
                                                                                   
                                                                                   
<div class="verbatim" id="verbatim-1">
ary.each{|x|
&#x00A0;<br />&#x00A0;&#x00A0;puts&#x00A0;x&#x00A0;*&#x00A0;x
&#x00A0;<br />}
</div>
<!--l. 94--><p class="nopar" >
<br /> </p><div class="caption" 
><span class="id">Figure&#x00A0;1: </span><span  
class="content">A program with an implicitly-terminating loop</span></div><!--tex4ht:label?: x1-5008r1 -->
                                                                                   
                                                                                   
       </div><hr class="endfigure" />
       <hr class="figure" /><div class="figure" 
>
                                                                                   
                                                                                   
<a 
 id="x1-5009r2"></a>
                                                                                   
                                                                                   
<div class="verbatim" id="verbatim-2">
i&#x00A0;=&#x00A0;0
&#x00A0;<br />while(i&#x00A0;&#x003C;&#x00A0;a.length)&#x00A0;{
&#x00A0;<br />&#x00A0;&#x00A0;puts&#x00A0;x&#x00A0;*&#x00A0;x
&#x00A0;<br />&#x00A0;&#x00A0;i&#x00A0;=&#x00A0;i&#x00A0;+&#x00A0;1
&#x00A0;<br />}
</div>
<!--l. 108--><p class="nopar" >
<br /> </p><div class="caption" 
><span class="id">Figure&#x00A0;2: </span><span  
class="content">A program with an arbitrary looping structure</span></div><!--tex4ht:label?: x1-5009r2 -->
                                                                                   
                                                                                   
       </div><hr class="endfigure" />
<a 
 id="dx1-5010"></a>
<!--l. 115--><p class="indent" >       The implementation in Figure <a 
href="#x1-5009r2">2<!--tex4ht:ref: fig:expterm --></a> is more complex than the one in Figure <a 
href="#x1-5008r1">1<!--tex4ht:ref: fig:impterm --></a>, but not
because of the size of the program. What makes it more complex is that it utilizes
an arbitrary looping structure - the while statement. In Figure <a 
href="#x1-5008r1">1<!--tex4ht:ref: fig:impterm --></a>, the looping
is inherently bound by the loop operator. In Figure <a 
href="#x1-5009r2">2<!--tex4ht:ref: fig:expterm --></a>, the programmer must
specifically act to make the loop terminate appropriately. There is no way an <span class="obeylines-h"><span class="verb"><span 
class="cmtt-12">each</span></span></span>
statement on its own will fail to halt. There are many ways in which a <span class="obeylines-h"><span class="verb"><span 
class="cmtt-12">while</span></span></span>
statement can fail to halt. The termination is decoupled from the loop construct
itself.
</p><!--l. 117--><p class="indent" >       Therefore, as a first pass to measure software complexity, the programmer can
simply count the number of open-ended looping structures (either as loops or recursive
functions) which occur in the program.
</p>
       <h3 class="sectionHead"><span class="titlemark">6   </span> <a 
 id="x1-60006"></a>Adding Axioms to Minimize Insight</h3>
<a 
 id="dx1-6001"></a>
<!--l. 122--><p class="noindent" >However, as is obvious from Figure <a 
href="#x1-5009r2">2<!--tex4ht:ref: fig:expterm --></a>, there are many well-understood conventions which
mitigate the complexity of certain kinds of open-ended looping structures. In that figure,
for instance, the variable <span 
class="cmmi-12">i </span>starts at zero, monotonically increases, and then terminates at a
predetermined stopping point, which will result in the loop&#8217;s termination. Even in cases
where this sequence of steps is not codified within the language using a special statement or
procedure, it is a well-understood looping convention. If the convention is followed
correctly, the loop will terminate.
<a 
 id="dx1-6002"></a>
</p><!--l. 125--><p class="indent" >       Gregory Chaitin formalized this idea in his algorithmic information theory. He
pointed out that while certain problems were unsolvable given a base set of axioms, by
incorporating additional axioms into the problem, solutions can be found. For instance,
following Chaitin, if God were to tell us how many programs of size <span 
class="cmmi-12">N </span>halted, that
information could be used to solve the halting problem for programs of size <span 
class="cmmi-12">N</span>
(<a 
href="#Xchaitin">Chaitin</a>,&#x00A0;<a 
href="#Xchaitin">1982</a>).<sup><a 
href="#ennote-1" id="enmark-1"><span 
class="cmr-8">1</span></a></sup>
</p><!--l. 127--><p class="indent" >       In the same way, when a convention for constraining repetition is discovered, it can
be incorporated into a canon of axioms which are also known to halt. And thus it should be
treated almost on the same level as a language construct which produces close-ended
loops, because language constructs enforce the validity of the axiom structurally,
while conventions require the programmer to manually follow the convention
correctly.
</p><!--l. 129--><p class="indent" >       This canon of axioms can be codified into an extensible static analysis tool to check
program complexity. Such a tool could consist of the set of potential non-terminating
constructs, as well as a &#8220;book of conventions&#8221; which are the known conventions
                                                                                   
                                                                                   
for ensuring termination. The tool would then measure the potential number of
non-terminating constructs which do not conform to a pattern in the &#8220;book of
conventions.&#8221;<sup><a 
href="#ennote-2" id="enmark-2"><span 
class="cmr-8">2</span></a></sup>
<a 
 id="dx1-6003"></a>
</p><!--l. 132--><p class="indent" >       In addition to the constructs which can be statically analyzed, some conventions
(often termed as &#8220;patterns&#8221;) will not be easily amenable to inference by software.
They should, however, at least be documented, and they can be manually marked
or removed after the fact. However, if the construct is not amenable to static
analysis, extra effort should be taken to review all implementations of the construct
manually.
<a 
 id="dx1-6004"></a>
</p><!--l. 135--><p class="indent" >       It should also be recognized that these axioms should be treated as first-class
insights&#8212;that is, the &#8220;book of conventions&#8221; should be considered a set of valuable
intellectual assets. As solutions to insight problems, the &#8220;book of conventions&#8221; is by
definition a set of solutions which are not immediately obvious, and, therefore, if a
convention is not recorded, and is therefore &#8220;lost,&#8221; it could well be a permanent loss of
insight for an organization. <a 
 id="dx1-6005"></a>
<a 
 id="dx1-6006"></a>
</p><!--l. 140--><p class="noindent" >
</p>
       <h3 class="sectionHead"><span class="titlemark">7   </span> <a 
 id="x1-70007"></a>Using the Metric</h3>
<a 
 id="dx1-7001"></a>
<!--l. 143--><p class="noindent" >The ultimate goal of the metric is to reduce the complexity of the software to zero. When a
pattern which solves a restricted subset of the halting problem is discovered, it can be
incorporated as a new axiom into the &#8220;book of conventions.&#8221; Therefore, if there are any
areas in the program which are marked as being complex, that means that it is still not
known if the program will even finish! If a developer has a new insight into why a
certain section of code will finish, this should be documented in the &#8220;book of
conventions.&#8221; If programmers cannot state why they think that the program
will finish, it should be reviewed or rewritten. If the code cannot be reworked
and the program cannot be proven to terminate, it should be considered highly
suspicious.
</p><!--l. 145--><p class="indent" >       In addition, areas of code which are complex given the constructs, but found in the
&#8220;book of conventions&#8221; should be flagged for a second-pass review to make sure the
conventions were followed appropriately. Such sections should also be flagged for
programmers making modifications to be sure that their modifications do not upset the
assumptions of the conventions. <a 
 id="dx1-7002"></a>
                                                                                   
                                                                                   
</p><!--l. 148--><p class="noindent" >
</p>
       <h3 class="sectionHead"><span class="titlemark">8   </span> <a 
 id="x1-80008"></a>Further Considerations</h3>
<!--l. 150--><p class="noindent" >While this metric is very useful, it is obviously not the last word on complexity metrics. It
does not technically supersede the other complexity metrics mentioned. Counting and
estimating lines of code are still useful planning tools. Cyclomatic complexity is still a
useful test coverage tool. However, this metric can be useful in identifying programming
patterns which are intrinsically problematic and help mitigate possible problems with
documentation, code review, and testing.
<a 
 id="dx1-8001"></a>
</p><!--l. 153--><p class="indent" >       For future development, similar ideas could be applied not just to the halting
complexity, but also to the complexity that variables are derived from. When the value of a
variable is determined by multiple loops, or conditions within loops, or other sorts of
non-linear mechanisms, the value of variables can be chaotic, even when they are not
themselves what determines if the problem halts. Extending these ideas to variable
calculation could allow for an even more comprehensive look at where program complexity
lies.
                                                                                   
                                                                                   
</p>
       <h3 class="likesectionHead"><a 
 id="x1-90008"></a>Notes</h3>
<!--l. 155--><p class="noindent" ></p><!--l. 4--><p class="indent" >       <a 
href="#enmark-1" id="ennote-1"><sup><span 
class="cmr-7">1</span></sup></a><span 
class="cmr-10">For an informal proof of this, consider that the issue that makes the halting problem difficult</span>
<span 
class="cmr-10">is that if a program is running indefinitely, it is impossible to tell whether or not it is just taking</span>
<span 
class="cmr-10">a long time and will finish eventually, or if it truly will never finish. However, if it is known that </span><span 
class="cmmi-10">k</span>
<span 
class="cmr-10">programs of size </span><span 
class="cmmi-10">N </span><span 
class="cmr-10">will halt, one can simply run all programs of size </span><span 
class="cmmi-10">N </span><span 
class="cmr-10">simultaneously. As long as</span>
<span 
class="cmr-10">the number of programs that have finished is smaller than </span><span 
class="cmmi-10">k</span><span 
class="cmr-10">, then there are some programs in that</span>
<span 
class="cmr-10">set which will halt. Once all </span><span 
class="cmmi-10">k </span><span 
class="cmr-10">programs finish, then it is needless to continue to run the remaining</span>
<span 
class="cmr-10">programs since it was given that exactly </span><span 
class="cmmi-10">k </span><span 
class="cmr-10">programs finish. Therefore, if the number of programs</span>
<span 
class="cmr-10">in a set which halt is known ahead of time, it is possible to determine the answer to all the halting</span>
<span 
class="cmr-10">problems in a finite length of time&#8212;the length of time will be the maximum runtime of the longest</span>
<span 
class="cmr-10">running halting program.</span>
</p><!--l. 179--><p class="indent" >       <a 
href="#enmark-2" id="ennote-2"><sup><span 
class="cmr-7">2</span></sup></a><span 
class="cmr-10">A   similar   procedure   was   independently   developed   by   </span><a 
href="#Xbringsjord"><span 
class="cmr-10">Bringsjord   et</span><span 
class="cmr-10">&#x00A0;al.</span></a><span 
class="cmr-10">&#x00A0;(</span><a 
href="#Xbringsjord"><span 
class="cmr-10">2006</span></a><span 
class="cmr-10">),</span>
<a 
href="#Xhertel"><span 
class="cmr-10">Hertel</span></a><span 
class="cmr-10">&#x00A0;(</span><a 
href="#Xhertel"><span 
class="cmr-10">2009</span></a><span 
class="cmr-10">),  and  </span><a 
href="#Xharland"><span 
class="cmr-10">Harland</span></a><span 
class="cmr-10">&#x00A0;(</span><a 
href="#Xharland"><span 
class="cmr-10">2007</span></a><span 
class="cmr-10">),  though  differing  in  many  aspects  and  applications.  Their</span>
<span 
class="cmr-10">solutions were to categorize non-halters rather than halters, and to do it based on runtime patterns</span>
<span 
class="cmr-10">rather than a static analysis of structural patterns in the program. They identified well-known</span>
<span 
class="cmr-10">patterns, data-mined for others, and then used a symbolic induction prover to match potential</span>
<span 
class="cmr-10">programs with these patterns. In addition, their purpose was for answering questions about computer</span>
<span 
class="cmr-10">science theory (specifically, the busy beaver problem) rather than assessing program complexity.</span>
                                                                                   
                                                                                   
</p>
       <h3 class="sectionHead"><a 
 id="x1-100008"></a>References</h3>
  <div class="thebibliography">
  <p class="bibitem" ><span class="biblabel">
<a 
 id="Xbartlett1"></a><span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span> Bartlett, J. (2014). Using Turing oracles in cognitive models of problem-solving.
  In J. Bartlett, D. Halsmer, &amp; M.&#x00A0;R. Hall (Eds.), <span 
class="cmti-12">Engineering and the ultimate</span>
  (pp.&#x00A0;99&#8211;122). Broken Arrow, OK: Blyth Institute Press.
  </p>
  <p class="bibitem" ><span class="biblabel">
<a 
 id="Xbringsjord"></a><span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>  Bringsjord,  S.,  Kellett,  O.,  Shilliday,  A.,  Taylor,  J.,  van  Heuveln,  B.,
  Yang,  Y.,  Baumes,  J.,  &amp;  Ross,  K.  (2006).     A  new  Gödelian  argument
  for  hypercomputing  minds  based  on  the  busy  beaver  problem.     <span 
class="cmti-12">Applied</span>
  <span 
class="cmti-12">Mathematics   and   Computations</span>,    176(2),    516&#8211;530.          Available    from
  <a 
href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.91.5786\&rep=rep1\&type=pdf" class="url" >http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.91.5786<span 
class="cmsy-10x-x-120">\</span>&amp;rep=rep1<span 
class="cmsy-10x-x-120">\</span>&amp;type=pdf</a>
  </p>
  <p class="bibitem" ><span class="biblabel">
<a 
 id="Xchaitin"></a><span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>       Chaitin,       G.       (1982).                    Gödel&#8217;s       theorem       and
  information.  <span 
class="cmti-12">International Journal of Theoretical Physics</span>, 21, 941&#8211;954.  Available
  from <a 
href="http://www.cs.auckland.ac.nz/~chaitin/georgia.html" class="url" >http://www.cs.auckland.ac.nz/<span 
class="cmsy-8">~</span>chaitin/georgia.html</a>
  </p>
  <p class="bibitem" ><span class="biblabel">
<a 
 id="Xfitzpatrick"></a><span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span> Fitzpatrick, J. (1997).  Applying the ABC metric to C, C++, and Java.  <span 
class="cmti-12">C++</span>
  <span 
class="cmti-12">Report</span>. Available from <a 
href="http://www.softwarerenovation.com/ABCMetric.pdf" class="url" >http://www.softwarerenovation.com/ABCMetric.pdf</a>
  </p>
  <p class="bibitem" ><span class="biblabel">
<a 
 id="Xharland"></a><span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span> Harland, J. (2007).  Analysis of busy beaver machines with inductive proofs.  In
  J. Gudmundsson &amp; B. Jay (Eds.), <span 
class="cmti-12">Cats&#8217;07: Proceedings of the 13th Australasian</span>
  <span 
class="cmti-12">symposium on theory of computing </span>(pp.&#x00A0;71&#8211;78).
  </p>
  <p class="bibitem" ><span class="biblabel">
<a 
 id="Xhertel"></a><span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>      Hertel,      J.      (2009).                 Computing      the      uncomputable
  rado  sigma  function:  An  automated,  symbolic  induction  prover  for  nonhalting
  Turing  machines.   <span 
class="cmti-12">The  Mathematica  Journal</span>,  11(2),  270&#8211;283.   Available  from
  <a 
href="http://www.mathematica-journal.com/issue/v11i2/contents/Hertel/Hertel.pdf" class="url" >http://www.mathematica-journal.com/issue/v11i2/contents/Hertel/Hertel.pdf</a>
  </p>
                                                                                   
                                                                                   
  <p class="bibitem" ><span class="biblabel">
<a 
 id="Xholloway"></a><span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>  Holloway,  E.  (2014).    Complex  specified  information  (CSI)  collecting.    In
  J.  Bartlett,  D.  Halsmer,  &amp;  M.&#x00A0;R.  Hall  (Eds.),  <span 
class="cmti-12">Engineering  and  the  ultimate</span>
  (pp.&#x00A0;153&#8211;166). Broken Arrow, OK: Blyth Institute Press.
  </p>
  <p class="bibitem" ><span class="biblabel">
<a 
 id="Xkearney"></a><span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span> Kearney, J.&#x00A0;K., Sedlmeyer, R.&#x00A0;L., Thompson, W.&#x00A0;B., Gray, M.&#x00A0;A., &amp; Adler,
  M.&#x00A0;A. (1986).  Software complexity measurement.  <span 
class="cmti-12">Communications of the ACM</span>,
  29(11), 1044&#8211;1050. Available from <a 
href="http://sunnyday.mit.edu/16.355/kearney.pdf" class="url" >http://sunnyday.mit.edu/16.355/kearney.pdf</a>
  </p>
  <p class="bibitem" ><span class="biblabel">
<a 
 id="Xmccabe"></a><span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>   McCabe,   T.&#x00A0;J.   (1976).      A   complexity   measure.      In   <span 
class="cmti-12">Proceedings  of</span>
  <span 
class="cmti-12">the  2nd  international  conference  on  software  engineering</span>.     Available  from
  <a 
href="http://www.literateprogramming.com/mccabe.pdf" class="url" >http://www.literateprogramming.com/mccabe.pdf</a>
  </p>
  <p class="bibitem" ><span class="biblabel">
<a 
 id="Xmcdirmid"></a><span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span>  McDirmid,  S.  (2006).   Turing  completeness  considered  harmful:  Component
  programming with a simple language.  Submitted for publication.  Available from
  <a 
href="http://lampwww.epfl.ch/~mcdirmid/papers/mcdirmid06turing.pdf" class="url" >http://lampwww.epfl.ch/<span 
class="cmsy-8">~</span>mcdirmid/papers/mcdirmid06turing.pdf</a>
</p>
  </div>
                                                                                   
                                                                                   
        
</body></html> 

                                                                                   


